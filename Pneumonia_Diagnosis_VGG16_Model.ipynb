{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer Learnign Model Keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "\n",
    "#top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = '/home/ec2-user/src/Data/ChestXray/chest_xray/train'\n",
    "validation_data_dir = '/home/ec2-user/src/Data/ChestXray/chest_xray/val'\n",
    "test_dir = '/home/ec2-user/src/Data/ChestXray/chest_xray/test'\n",
    "nb_train_samples = 5216\n",
    "nb_validation_samples = 16\n",
    "batch_size = 1\n",
    "nb_test_samples = 624\n",
    "test_batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# reading in image data from training and validation steps \n",
    "\n",
    "# use ImageDataGenerator to normalize/augment \n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# use flow_from_directory method to resize/pre-process \n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "#use model predict to create bottleneck weights from VGG16 & save to .npy file\n",
    "\n",
    "bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "np.save(open('bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "bottleneck_features_test = model.predict_generator(\n",
    "        generator, nb_test_samples // test_batch_size)\n",
    "np.save(open('bottleneck_features_test.npy', 'wb'), bottleneck_features_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and create labels in sequential order\n",
    "\n",
    "# Normal 0; Pneumonia 1 \n",
    "\n",
    "train_data = np.load(open('bottleneck_features_train.npy','rb'))\n",
    "train_labels = np.array([0] * (1341) + [1] * (3875))\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy','rb'))\n",
    "validation_labels = np.array([0] * (8) + [1] * (8))\n",
    "\n",
    "test_data = np.load(open('bottleneck_features_test.npy','rb'))\n",
    "test_labels = np.array([0] * (234) + [1] * (390))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 7, 7, 512)\n",
      "(5216,)\n",
      "(16, 7, 7, 512)\n",
      "(16,)\n",
      "(624, 7, 7, 512)\n",
      "(624,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(validation_data.shape)\n",
    "print(validation_labels.shape)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 500)               12544500  \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 12,670,001\n",
      "Trainable params: 12,670,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create dense fully connected model to add to base pre-configured model \n",
    "# inputs from trained bottled features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "adam = Adam(lr=0.0001, decay=0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.2728 - acc: 0.8936Epoch 00000: val_loss improved from inf to 0.73149, saving model to model.weights.best.hdf5\n",
      "5216/5216 [==============================] - 86s - loss: 0.2727 - acc: 0.8936 - val_loss: 0.7315 - val_acc: 0.6875\n",
      "Epoch 2/40\n",
      "5213/5216 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9589Epoch 00001: val_loss improved from 0.73149 to 0.47071, saving model to model.weights.best.hdf5\n",
      "5216/5216 [==============================] - 86s - loss: 0.1158 - acc: 0.9590 - val_loss: 0.4707 - val_acc: 0.7500\n",
      "Epoch 3/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9672Epoch 00002: val_loss improved from 0.47071 to 0.12741, saving model to model.weights.best.hdf5\n",
      "5216/5216 [==============================] - 86s - loss: 0.0893 - acc: 0.9672 - val_loss: 0.1274 - val_acc: 0.9375\n",
      "Epoch 4/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9722Epoch 00003: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0733 - acc: 0.9722 - val_loss: 0.3434 - val_acc: 0.8750\n",
      "Epoch 5/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9793Epoch 00004: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0613 - acc: 0.9793 - val_loss: 0.5731 - val_acc: 0.8750\n",
      "Epoch 6/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9801Epoch 00005: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0596 - acc: 0.9801 - val_loss: 0.6131 - val_acc: 0.8750\n",
      "Epoch 7/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9839Epoch 00006: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0499 - acc: 0.9839 - val_loss: 0.4913 - val_acc: 0.8750\n",
      "Epoch 8/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9850Epoch 00007: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0453 - acc: 0.9850 - val_loss: 0.4841 - val_acc: 0.8750\n",
      "Epoch 9/40\n",
      "5213/5216 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9852Epoch 00008: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0374 - acc: 0.9852 - val_loss: 0.4300 - val_acc: 0.8750\n",
      "Epoch 10/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9868Epoch 00009: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0364 - acc: 0.9868 - val_loss: 0.7583 - val_acc: 0.8750\n",
      "Epoch 11/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9885Epoch 00010: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0336 - acc: 0.9885 - val_loss: 0.3922 - val_acc: 0.8750\n",
      "Epoch 12/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9885Epoch 00011: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0313 - acc: 0.9885 - val_loss: 0.4860 - val_acc: 0.8750\n",
      "Epoch 13/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9906Epoch 00012: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0270 - acc: 0.9906 - val_loss: 0.6203 - val_acc: 0.8750\n",
      "Epoch 14/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9916Epoch 00013: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0257 - acc: 0.9914 - val_loss: 0.3465 - val_acc: 0.8750\n",
      "Epoch 15/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9923Epoch 00014: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0222 - acc: 0.9923 - val_loss: 0.4968 - val_acc: 0.8750\n",
      "Epoch 16/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9939Epoch 00015: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0176 - acc: 0.9939 - val_loss: 0.7994 - val_acc: 0.8750\n",
      "Epoch 17/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9948Epoch 00016: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0174 - acc: 0.9948 - val_loss: 0.5943 - val_acc: 0.8750\n",
      "Epoch 18/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9942Epoch 00017: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0195 - acc: 0.9942 - val_loss: 0.5685 - val_acc: 0.8750\n",
      "Epoch 19/40\n",
      "5213/5216 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9950Epoch 00018: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0163 - acc: 0.9950 - val_loss: 0.4144 - val_acc: 0.8750\n",
      "Epoch 20/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9937Epoch 00019: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0153 - acc: 0.9937 - val_loss: 0.6792 - val_acc: 0.8750\n",
      "Epoch 21/40\n",
      "5213/5216 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9929Epoch 00020: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0162 - acc: 0.9929 - val_loss: 0.7832 - val_acc: 0.8750\n",
      "Epoch 22/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9941Epoch 00021: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0143 - acc: 0.9941 - val_loss: 0.7162 - val_acc: 0.8750\n",
      "Epoch 23/40\n",
      "5213/5216 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9962Epoch 00022: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0114 - acc: 0.9962 - val_loss: 0.6413 - val_acc: 0.8750\n",
      "Epoch 24/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9956Epoch 00023: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0108 - acc: 0.9956 - val_loss: 1.0905 - val_acc: 0.8750\n",
      "Epoch 25/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9956Epoch 00024: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0126 - acc: 0.9956 - val_loss: 0.4934 - val_acc: 0.8750\n",
      "Epoch 26/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9965Epoch 00025: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0098 - acc: 0.9965 - val_loss: 0.7282 - val_acc: 0.8750\n",
      "Epoch 27/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9958Epoch 00026: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0106 - acc: 0.9958 - val_loss: 0.5142 - val_acc: 0.8750\n",
      "Epoch 28/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9964Epoch 00027: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0088 - acc: 0.9964 - val_loss: 0.8586 - val_acc: 0.8750\n",
      "Epoch 29/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9964Epoch 00028: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0098 - acc: 0.9964 - val_loss: 1.0683 - val_acc: 0.8750\n",
      "Epoch 30/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9975Epoch 00029: val_loss did not improve\n",
      "5216/5216 [==============================] - 86s - loss: 0.0084 - acc: 0.9975 - val_loss: 0.9442 - val_acc: 0.8750\n",
      "Epoch 31/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9971Epoch 00030: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0071 - acc: 0.9971 - val_loss: 1.0393 - val_acc: 0.8750\n",
      "Epoch 32/40\n",
      "5215/5216 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9971Epoch 00031: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0083 - acc: 0.9971 - val_loss: 1.0701 - val_acc: 0.8750\n",
      "Epoch 33/40\n",
      "5213/5216 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9960Epoch 00032: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216/5216 [==============================] - 86s - loss: 0.0088 - acc: 0.9960 - val_loss: 0.7907 - val_acc: 0.8750\n",
      "Epoch 34/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9969Epoch 00033: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0074 - acc: 0.9969 - val_loss: 0.8593 - val_acc: 0.8750\n",
      "Epoch 35/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9979Epoch 00034: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0073 - acc: 0.9979 - val_loss: 0.9561 - val_acc: 0.8750\n",
      "Epoch 36/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9975Epoch 00035: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0079 - acc: 0.9975 - val_loss: 1.1023 - val_acc: 0.8750\n",
      "Epoch 37/40\n",
      "5212/5216 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9973Epoch 00036: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0063 - acc: 0.9973 - val_loss: 0.9716 - val_acc: 0.8750\n",
      "Epoch 38/40\n",
      "5213/5216 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9981Epoch 00037: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0056 - acc: 0.9981 - val_loss: 0.9648 - val_acc: 0.8750\n",
      "Epoch 39/40\n",
      "5213/5216 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9977Epoch 00038: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0060 - acc: 0.9977 - val_loss: 1.1656 - val_acc: 0.8750\n",
      "Epoch 40/40\n",
      "5214/5216 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9971Epoch 00039: val_loss did not improve\n",
      "5216/5216 [==============================] - 85s - loss: 0.0074 - acc: 0.9971 - val_loss: 0.8043 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# fit combined models to data\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "epochs = 40\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "predict = model.fit(train_data, train_labels,\n",
    "             epochs=epochs,\n",
    "             batch_size=batch_size,\n",
    "             validation_data=(validation_data, validation_labels), callbacks=[checkpointer], verbose =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'acc', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "print(predict.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'acc', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78cd147cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(predict.history.keys())\n",
    "plt.plot(predict.history['acc'])\n",
    "plt.plot(predict.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best trained weights\n",
    "\n",
    "model.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/624 [=================>............] - ETA: 0s\n",
      " Test accuracy: [0.55903827134543693, 0.86858974358974361]\n"
     ]
    }
   ],
   "source": [
    "# print model accuracy on the test data set\n",
    "\n",
    "score = model.evaluate(test_data, test_labels, verbose=1)\n",
    "print('\\n', 'Test accuracy:', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/624 [===================>..........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data,verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =[]\n",
    "import math\n",
    "\n",
    "for x in predictions:\n",
    "    a = np.round(x,0)\n",
    "    pred.append(int(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = list(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[157  77]\n",
      " [  5 385]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78cca90cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATAAAAD0CAYAAAAc9XrlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njLYDL58AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78ccfccdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as pl\n",
    "\n",
    "pl.figure()\n",
    "matrix = confusion_matrix(truth, pred)\n",
    "print(matrix)\n",
    "a = pl.matshow(matrix)\n",
    "\n",
    "pl.xticks(range(2), ['Normal', 'Pneumonia'])\n",
    "pl.yticks(range(2), ['Normal', 'Pneumonia'])\n",
    "\n",
    "pl.colorbar(a)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.987179487179\n",
      "recall:  0.833333333333\n"
     ]
    }
   ],
   "source": [
    "trueNegative,  falseNegative, falsePositive, truePositive,  = matrix.ravel()\n",
    "\n",
    "# 0 normal, # 1 healthy\n",
    "\n",
    "precision = truePositive/(truePositive+falsePositive)\n",
    "recall = truePositive/(truePositive+falseNegative)\n",
    "\n",
    "print(\"precision: \", precision)\n",
    "\n",
    "print(\"recall: \", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
